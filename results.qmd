# Results

## Bias

```{r fig.cap="", echo=FALSE, out.width="80%", out.height="auto"}
knitr::include_graphics("images/wa/bias0.png")
```

::: column-margin
-   `u` represents those where no proxies are utilized
-   `SL` represents those where super learner was used with the following 4 candidate learners
    1.  Logistic regression
    2.  MARS (Multivariate Adaptive Regression Splines)
    3.  LASSO
    4.  XGBoost (Extreme Gradient Boosting)
-   `TMLE` represents those where TMLE was used
-   `DC` represents double cross-fit.

Same super learner used for `SL` and `TMLE` methods.
:::

::: callout-tip
Clearly using proxies improve bias estimates
:::

## Bias (used proxies)

```{r fig.cap="", echo=FALSE, out.width="80%", out.height="auto"}
knitr::include_graphics("images/wa/bias.png")
```

::: column-margin
- `SL` methods seem to have negligible improvements over `non-SL` methods in terms of bias.
- `TMLE` methods winning in terms of bias.
::: 

## MSE

```{r fig.cap="", echo=FALSE, out.width="80%", out.height="auto"}
knitr::include_graphics("images/wa/mse.png")
```

::: column-margin
- `TMLE` methods winning in terms of MSE.
::: 

## Relative Error

```{r fig.cap="", echo=FALSE, out.width="80%", out.height="auto"}
knitr::include_graphics("images/wa/relerror.png")
```

::: column-margin
- `TMLE` methods are have worse relative % error in Model SE estimation.
- `SL` methods are winners.
::: 

## Coverage

```{r fig.cap="", echo=FALSE, out.width="80%", out.height="auto"}
knitr::include_graphics("images/wa/cover.png")
```

::: column-margin
- `TMLE` methods are have worse 95% coverage (below 85%).
- `SL` methods are winners.
- But some of these methods were biased, so hard to compare.
::: 

## Bias eliminated coverage

```{r fig.cap="", echo=FALSE, out.width="80%", out.height="auto"}
knitr::include_graphics("images/wa/becover.png")
```

::: column-margin
- `TMLE` methods are have worse 95% bias eliminated coverage (below 85%).
::: 